import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import numpy as np
import os
from torch.utils.data import DataLoader, TensorDataset
from data.trend_data_processor import (
    Configs,
    Dataset,
    create_loaders,  # ç¡®ä¿è¿™ä¸ªå‡½æ•°åœ¨ processor é‡Œèƒ½è¿”å›ä¸‰ä¸ª loader
    evaluate_metrics,
    DEVICE,
    DATA_FOLDER
)
from model.BaseTrend_model import TrendForecaster
from torch.utils.tensorboard import SummaryWriter


# ---------------------------------------------------------
# 1. å¯¼å‡ºç”¨äº ShockNet çš„æ•°æ®é›† (pklæ ¼å¼)
# ---------------------------------------------------------
def export_dataset_for_shocknet(dataset, output_path="data/cmin_US_price_label_data.pkl"):
    """
    å°† Dataset ä¸­çš„æ•°æ®å¯¼å‡ºä¸º Pickle æ–‡ä»¶ï¼Œä¾› ShockNet è¯»å–ã€‚
    """
    print(f"\n=== æ­£åœ¨å¯¼å‡ºç”¨äº ShockNet çš„ä»·æ ¼ä¸æ ‡ç­¾æ•°æ® ===")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    data_list = []

    try:
        print("æ­£åœ¨è½¬æ¢æ•°æ®æ ¼å¼ (å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ)...")
        # éå†æ•°æ®é›†çš„å†…éƒ¨æ•°æ®åˆ—è¡¨
        for item in dataset.data:
            # æœŸæœ› item ä¸º (x, y_act, y_base, y_shock, date, ticker)
            x, y_act, y_base, y_shock, date, ticker = item

            data_list.append({
                'date': str(date.date()) if hasattr(date, 'date') else str(date),
                'ticker': ticker,
                'X_history': x.numpy(),
                'Y_Actual': y_act.item(),
                'Y_Base_Logits': y_base.item(),
                'Y_Shock_Value': y_shock.item()
            })

        df = pd.DataFrame(data_list)
        df.to_pickle(output_path)
        print(f"å¯¼å‡ºæˆåŠŸ! æ–‡ä»¶å·²ä¿å­˜è‡³: {output_path}")
        print(f"æ€»æ ·æœ¬æ•°: {len(df)}")

    except Exception as e:
        print(f"å¯¼å‡ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


# ---------------------------------------------------------
# 2. è®­ç»ƒå¾ªç¯
# ---------------------------------------------------------
def train_model(model, train_loader, val_loader, configs, epochs=150, learning_rate=2e-4):
    log_dir = f'runs/TrendNet_{pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")}'
    writer = SummaryWriter(log_dir)
    print(f"TensorBoard æ—¥å¿—å°†å†™å…¥: {log_dir}")

    DEVICE = next(model.parameters()).device
    positive_weight = torch.tensor(0.908, dtype=torch.float32).to(DEVICE)
    criterion = nn.BCEWithLogitsLoss(pos_weight=positive_weight)

    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='max', factor=0.5, patience=10, min_lr=1e-6
    )

    best_val_mcc = -1.0  # æ”¹ä¸ºç›‘æ§ MCCï¼Œå› ä¸ºå®ƒæ˜¯æˆ‘ä»¬æœ€å…³å¿ƒçš„æŒ‡æ ‡
    best_threshold_value = 0.5
    BEST_MODEL_PATH = 'best_trendnet.pth'

    print(f"\n=== å¼€å§‹ TrendNet è®­ç»ƒ (è®¾å¤‡: {DEVICE}) ===")

    for epoch in range(epochs):
        model.train()
        train_loss_sum = 0

        # --- è®­ç»ƒè¿­ä»£ ---
        for i, (X, y) in enumerate(train_loader):
            X = X.to(DEVICE)
            y = y.to(DEVICE).float()
            optimizer.zero_grad()
            outputs = model(X)
            loss = criterion(outputs.view(-1), y.view(-1))
            loss.backward()
            optimizer.step()
            train_loss_sum += loss.item()

        avg_train_loss = train_loss_sum / len(train_loader)
        writer.add_scalar('Loss/Train', avg_train_loss, epoch)

        # --- éªŒè¯è¯„ä¼° ---
        model.eval()
        all_probs = []
        all_targets = []

        with torch.no_grad():
            for X, y in val_loader:
                X = X.to(DEVICE)
                y = y.to(DEVICE).float()
                logits = model(X)
                pred_prob = torch.sigmoid(logits).view(-1)
                all_probs.extend(pred_prob.cpu().numpy())
                all_targets.extend(y.view(-1).cpu().numpy())

        val_metrics = evaluate_metrics(np.array(all_probs), np.array(all_targets))
        current_mcc = val_metrics['mcc']
        current_f1 = val_metrics['f1']

        writer.add_scalar('Metrics/Val_F1', current_f1, epoch)
        writer.add_scalar('Metrics/Val_MCC', current_mcc, epoch)

        log_msg = f"Epoch {epoch + 1}: TrainLoss={avg_train_loss:.4f} | Val MCC={current_mcc:.4f} | F1={current_f1:.4f}"

        # è°ƒåº¦å™¨æ­¥è¿›
        scheduler.step(current_mcc)

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if current_mcc > best_val_mcc:
            best_val_mcc = current_mcc
            best_threshold_value = val_metrics['threshold']
            torch.save(model.state_dict(), BEST_MODEL_PATH)
            log_msg += " ğŸ† [Saved Best]"

        print(log_msg)

    print(f"è®­ç»ƒç»“æŸã€‚æœ€ä½³éªŒè¯é›† MCC: {best_val_mcc:.4f}")
    writer.close()
    return model, best_threshold_value


# ---------------------------------------------------------
# 3. ä¿¡å·ç”Ÿæˆå‡½æ•° (ç”Ÿæˆ CSV)
# ---------------------------------------------------------
def generate_trend_scores(dataset, model_path="best_trendnet.pth", best_threshold=0.50):
    configs = Configs()
    model = TrendForecaster(configs, prediction_horizon=1).to(DEVICE)

    if os.path.exists(model_path):
        state_dict = torch.load(model_path, map_location=DEVICE, weights_only=True)
        model.load_state_dict(state_dict)
        print(f"åŠ è½½æƒé‡æˆåŠŸï¼Œå‡†å¤‡ç”Ÿæˆå…¨é‡åˆ†æ•°...")
    else:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {model_path}ã€‚")
        return

    model.eval()

    # æå–æ‰€æœ‰æ•°æ®è¿›è¡Œæ¨ç†
    X_all = torch.stack([dataset.data[i][0] for i in range(len(dataset.data))])
    all_loader = DataLoader(TensorDataset(X_all), batch_size=256, shuffle=False)
    all_probs = []

    with torch.no_grad():
        for batch in all_loader:
            X = batch[0].to(DEVICE)
            logits = model(X)
            pred_prob = torch.sigmoid(logits).view(-1)
            all_probs.extend(pred_prob.cpu().numpy())

    # æå–å…ƒæ•°æ®
    metadata = dataset.data
    predicted_signal = (np.array(all_probs) > best_threshold).astype(int)

    df_scores = pd.DataFrame({
        'Target_Date': [d[4] for d in metadata],
        'Ticker': [d[5] for d in metadata],
        'P_Trend': all_probs,
        'Signal': predicted_signal
    })

    df_scores.to_csv("trend_base_scores.csv", index=False)
    print(f"è¶‹åŠ¿ä¿¡å·å·²ä¿å­˜è‡³ trend_base_scores.csvã€‚")


# ---------------------------------------------------------
# ğŸ”¥ğŸ”¥ã€æ–°å¢ã€‘4. æµ‹è¯•é›†è¯„ä¼°å‡½æ•° ğŸ”¥ğŸ”¥
# ---------------------------------------------------------
def test_trend_model(dataset, batch_size=64):
    print(f"\n=== æ­£åœ¨è¯„ä¼° TrendNet (Baseline) åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç° ===")

    # é‡æ–°è·å– test_loader (åˆ©ç”¨ create_loaders çš„åˆ†å‰²é€»è¾‘)
    _, _, test_loader = create_loaders(dataset, batch_size=batch_size)

    configs = Configs()
    model = TrendForecaster(configs, prediction_horizon=1).to(DEVICE)

    load_path = 'best_trendnet.pth'
    if os.path.exists(load_path):
        model.load_state_dict(torch.load(load_path, map_location=DEVICE, weights_only=True))
        print(f"å·²åŠ è½½æœ€ä½³æ¨¡å‹: {load_path}")
    else:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œæ— æ³•æµ‹è¯•ã€‚")
        return

    model.eval()
    all_probs = []
    all_targets = []

    with torch.no_grad():
        for X, y in test_loader:
            X = X.to(DEVICE)
            y = y.to(DEVICE).float()

            logits = model(X)
            pred_prob = torch.sigmoid(logits).view(-1)

            all_probs.extend(pred_prob.cpu().numpy())
            all_targets.extend(y.view(-1).cpu().numpy())

    # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    metrics = evaluate_metrics(np.array(all_probs), np.array(all_targets))

    print("-" * 40)
    print(f"ğŸ“Š TrendNet (Baseline) æµ‹è¯•é›†æœ€ç»ˆæˆç»©:")
    print(f"   MCC : {metrics['mcc']:.4f}")
    print(f"   F1  : {metrics['f1']:.4f}")
    print(f"   AUC : {metrics['auc']:.4f}")
    print(f"   ACC : {metrics['accuracy']:.4f}")
    print("-" * 40)


# ---------------------------------------------------------
# 5. ä¸»ç¨‹åºå…¥å£
# ---------------------------------------------------------
def run_trend_phase():
    configs = Configs()

    # 1. åˆå§‹åŒ–æ•°æ®
    dataset = Dataset(DATA_FOLDER, past_window=configs.seq_len)

    # 2. å¯¼å‡ºæ•°æ®ç»™ ShockNet
    export_dataset_for_shocknet(dataset, output_path="data/cmin_US_price_label_data.pkl")

    # 3. åˆ›å»º DataLoader
    train_loader, val_loader, _ = create_loaders(dataset, batch_size=64)

    # 4. åˆå§‹åŒ–æ¨¡å‹
    model = TrendForecaster(configs, prediction_horizon=1).to(DEVICE)

    # 5. è®­ç»ƒ
    # è®­ç»ƒåä¼šä¿å­˜ best_trendnet.pth
    trained_model, best_threshold_value = train_model(
        model, train_loader, val_loader, configs, epochs=150, learning_rate=2e-4
    )

    # 6. ç”Ÿæˆå…¨é‡åˆ†æ•° CSV (å¯é€‰ï¼Œç”¨äºåˆ†æ)
    generate_trend_scores(dataset, model_path='best_trendnet.pth', best_threshold=best_threshold_value)

    # ğŸ”¥ğŸ”¥ğŸ”¥ 7. ç«‹å³åœ¨æµ‹è¯•é›†ä¸Šè·‘åˆ† ğŸ”¥ğŸ”¥ğŸ”¥
    test_trend_model(dataset)


if __name__ == "__main__":
    if not os.path.exists('data'):
        os.makedirs('data')
    run_trend_phase()