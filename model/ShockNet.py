import torch
import torch.nn as nn
import torch.nn.functional as F
from model.BaseTrend_model import TrendForecaster


class NeuralMemoryBank(nn.Module):
    """ÂéÜÂè≤‰∫ã‰ª∂Ê®°ÂºèÂ∫ì"""

    def __init__(self, memory_slots, feature_dim):
        super(NeuralMemoryBank, self).__init__()
        self.memory_slots = memory_slots
        self.feature_dim = feature_dim

        # ËÆ∞ÂøÜÈîÆÂÄºÂØπ
        self.memory_keys = nn.Parameter(torch.randn(memory_slots, feature_dim))
        self.memory_values = nn.Parameter(torch.randn(memory_slots, feature_dim))

        nn.init.xavier_uniform_(self.memory_keys)
        nn.init.xavier_uniform_(self.memory_values)

    def forward(self, query_vector):
        # 1. ËÆ°ÁÆóÁõ∏‰ººÂ∫¶ [Batch, Slots]
        scores = torch.matmul(query_vector, self.memory_keys.t())
        attn_weights = F.softmax(scores, dim=-1)

        # 2. Âä†ÊùÉËûçÂêà [Batch, Dim]
        memory_output = torch.matmul(attn_weights, self.memory_values)
        return memory_output, attn_weights


class ShockNet(nn.Module):
    def __init__(self, configs):
        super(ShockNet, self).__init__()

        self.d_trend = configs.d_model
        self.d_text = configs.d_text
        self.d_hidden = configs.d_hidden  # 128
        self.memory_slots = configs.memory_slots

        # --- 1. Âä®ÊÄÅÂä†ÊùÉËÅöÂêàÊ®°Âùó ---
        self.trend_proj = nn.Linear(self.d_trend, self.d_text)
        self.gating_layer = nn.Sequential(
            nn.Linear(self.d_text * 2, self.d_text),
            nn.ReLU(),
            nn.Linear(self.d_text, self.d_text),
            nn.Sigmoid()
        )

        # --- 2. Â±ÄÈÉ®Êü•ËØ¢ÊûÑÈÄ†Â±Ç ---
        self.query_encoder = nn.Sequential(
            nn.Linear(self.d_text + self.d_trend, self.d_hidden),
            nn.LayerNorm(self.d_hidden),
            nn.ReLU()
        )

        # --- 3. ÂéÜÂè≤‰∫ã‰ª∂Ê®°ÂºèÂ∫ì ---
        self.memory_bank = NeuralMemoryBank(self.memory_slots, self.d_hidden)

        # --- 4. ËûçÂêà‰∏éÊé®ÁêÜÁΩëÁªú ---
        self.fusion_layer = nn.Sequential(
            nn.Linear(self.d_hidden * 2, self.d_hidden),
            nn.LayerNorm(self.d_hidden),
            nn.ReLU()
        )

        # 5. ÂÜ≤ÂáªÁõÆÊ†áÂµåÂÖ•ÁΩëÁªú E(.)
        # üì¢ ‰øÆÊ≠£ÔºöËæìÂá∫Áª¥Â∫¶ÂøÖÈ°ªÊòØ d_hidden (128) ‰ª•‰æøËÆ°ÁÆó Triplet Loss
        self.target_embedding_net = nn.Sequential(
            nn.Linear(1, 64),  # ËæìÂÖ•ÊòØÊ†áÈáè (1)
            nn.ReLU(),
            nn.Linear(64, self.d_hidden)  # ËæìÂá∫ 128
        )

        # 6. Êé®ÁêÜÂ§¥
        self.inference_head = nn.Sequential(
            nn.Linear(self.d_hidden, 64), nn.ReLU(),
            nn.Linear(64, 1), nn.Tanh()  # ËæìÂá∫ÂÜ≤ÂáªÂÄº [-1, 1]
        )

    def forward(self, trend_features, event_embeddings, intervention_type='factual'):
        """
        Returns: shock_pred, fused_feat (ÁâπÂæÅÂµåÂÖ•), query_vector
        """

        # 1.1 Âä®ÊÄÅÂä†ÊùÉËÅöÂêà
        trend_projected = self.trend_proj(trend_features)
        combined_for_gate = torch.cat([trend_projected, event_embeddings], dim=-1)
        gate = self.gating_layer(combined_for_gate)

        # 1.2 Âèç‰∫ãÂÆûÂπ≤È¢ÑÈÄªËæë
        if intervention_type == 'counterfactual':
            # Âèç‰∫ãÂÆûÔºöÂº∫Âà∂Â∞Ü‰∫ã‰ª∂ÁâπÂæÅÁΩÆÈõ∂ÔºåÊ®°ÊãüÊó†‰∫ã‰ª∂ÂèëÁîü
            # ËøôÈáåÁöÑ shock_features ÂÆûÈôÖ‰∏äÂè™ÊúâË∂ãÂäø‰ø°ÊÅØÊäïÂ∞ÑËøáÊù•ÁöÑÂΩ±Â≠ê
            shock_features = torch.zeros_like(event_embeddings)
        else:
            # ‰∫ãÂÆûÔºöÊ≠£Â∏∏ËÆ°ÁÆóÔºåÂåÖÂê´‰∫ã‰ª∂‰ø°ÊÅØ
            shock_features = event_embeddings * gate

        # 2. Â±ÄÈÉ®Êü•ËØ¢ÊûÑÈÄ†
        concat_features = torch.cat([shock_features, trend_features], dim=-1)
        query_vector = self.query_encoder(concat_features)

        # 3. ËÆ∞ÂøÜÊ£ÄÁ¥¢ (ÊøÄÊ¥ª)
        memory_feat, _ = self.memory_bank(query_vector)

        # 4. ËûçÂêà‰∏éÊé®ÁêÜ
        final_feat_input = torch.cat([query_vector, memory_feat], dim=-1)

        # fused_feat ÊòØÁî®‰∫éËÆ°ÁÆó Triplet/Ortho Loss ÁöÑÊ†∏ÂøÉÂêëÈáè
        fused_feat = self.fusion_layer(final_feat_input)

        shock_pred = self.inference_head(fused_feat)

        return shock_pred, fused_feat, query_vector


# --- CausalShockNet ÊúÄÁªàÈõÜÊàêÊ®°Âûã ---
class CausalShockNet(nn.Module):
    def __init__(self, configs):
        super(CausalShockNet, self).__init__()
        self.configs = configs

        # 1. Âü∫Á°ÄË∂ãÂäøÊ®°Âûã (Áî®‰∫éÊèêÂèñ pure inertia)
        # ÂÅáËÆæÊÇ®Â∑≤ÁªèÊúâËÆ≠ÁªÉÂ•ΩÁöÑ TrendForecasterÔºåÊàñËÄÖÂú®ËøôÈáåÈáçÊñ∞ÂàùÂßãÂåñ
        self.trend_model = TrendForecaster(configs)

        # 2. ‰∫ã‰ª∂ÁºñÁ†ÅÂô® (Â∞Ü 768 Áª¥ BERT ÂêëÈáèÊò†Â∞ÑÂà∞ d_model Áª¥Â∫¶)
        self.event_encoder = nn.Sequential(
            nn.Linear(configs.d_text, configs.d_hidden),
            nn.ReLU(),
            nn.Dropout(configs.dropout),
            nn.Linear(configs.d_hidden, configs.d_model)
        )

        # 3. ËûçÂêàÈó®ÊéßÊú∫Âà∂ (Gating / Mixer)
        # Áî®‰∫éÂ∞Ü‰∫ã‰ª∂ÂÜ≤ÂáªÊ≥®ÂÖ•Âà∞Ë∂ãÂäøÁâπÂæÅ‰∏≠
        self.fusion_gate = nn.Sequential(
            nn.Linear(configs.d_model * 2, configs.d_model),
            nn.Sigmoid()
        )

        # üî•üî•üî•„ÄêÊ†∏ÂøÉ‰øÆÊîπÁÇπ 1„ÄëÊñ∞Â¢û LayerNorm Â±Ç üî•üî•üî•
        # Âº∫Âà∂ÁâπÂæÅÂΩí‰∏ÄÂåñÔºåËß£ÂÜ≥Ê®°ÈïøÂ§±Ë°°ÈóÆÈ¢ò
        # ËøôÈáåÁöÑ d_model Â∫îËØ•ÊòØ 15
        self.feature_norm = nn.LayerNorm(configs.d_model)

        # 4. ÊúÄÁªàÂàÜÁ±ªÈ¢ÑÊµãÂ§¥ (Ê†πÊçÆËûçÂêàÂêéÁöÑÁâπÂæÅÈ¢ÑÊµãÊ∂®Ë∑å)
        self.classifier = nn.Linear(configs.d_model, 1)

        # 5. ËæÖÂä©ÁΩëÁªú: Áî®‰∫é Triplet Loss ÁöÑ Anchor Embedding (Â∞ÜÊ†áÈáè Shock Value Êò†Â∞Ñ‰∏∫ÂêëÈáè)
        # ËøôÊ†∑ÊâçËÉΩËÆ°ÁÆó Triplet Loss: Dist(Anchor, Positive) vs Dist(Anchor, Negative)
        self.target_embedding_net = nn.Sequential(
            nn.Linear(1, configs.d_hidden),
            nn.ReLU(),
            nn.Linear(configs.d_hidden, configs.d_model)
            # Ê≥®ÊÑèÔºöAnchor ËæìÂá∫ÊúÄÂ•Ω‰πüËøá‰∏Ä‰∏ã LayerNormÔºåÊàñËÄÖÂú® Loss Â§ñÈù¢ÂΩí‰∏ÄÂåñ
        )

    def forward(self, x_history, event_emb):
        """
        x_history: [Batch, Seq_Len, Features]
        event_emb: [Batch, d_text]
        """

        # --- A. Âèç‰∫ãÂÆûÂàÜÊîØ (Counterfactual Branch) ---
        # ‰πüÂ∞±ÊòØÔºöÂ¶ÇÊûúÊ≤°ÊúâÂèëÁîü‰∫ã‰ª∂ÔºåÂ∏ÇÂú∫ÂéüÊú¨ÁöÑË∂ãÂäø (Pure Trend)
        # ‰ªéË∂ãÂäøÊ®°Âûã‰∏≠Ëé∑ÂèñÁâπÂæÅ„ÄÇÊ≥®ÊÑèÔºöBaseTrend_model ÈúÄË¶ÅÊîØÊåÅ return_feature=True
        trend_logits, feat_cf_raw = self.trend_model(x_history, return_feature=True)

        # --- B. ‰∫ãÂÆûÂàÜÊîØ (Factual Branch) ---
        # ‰πüÂ∞±ÊòØÔºöÁúüÂÆûÂèëÁîüÁöÑ‰∏ñÁïå (Trend + Shock)

        # 1. ÁºñÁ†Å‰∫ã‰ª∂
        e_emb = self.event_encoder(event_emb)  # [Batch, d_model]

        # 2. ËûçÂêàÊú∫Âà∂ (ËøôÈáåÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÂä†Ê≥ïÊàñÈó®ÊéßÁ§∫‰æãÔºåÂÖ∑‰ΩìËßÜÊÇ®ÂéüÈÄªËæëËÄåÂÆö)
        # ÊãºÊé• Ë∂ãÂäøÁâπÂæÅ Âíå ‰∫ã‰ª∂ÁâπÂæÅ
        combined = torch.cat([feat_cf_raw, e_emb], dim=1)
        gate = self.fusion_gate(combined)

        # ‰∫ãÂÆûÁâπÂæÅ = Ë∂ãÂäø + Èó®Êéß * ‰∫ã‰ª∂ÂÜ≤Âáª
        # (ÊÆãÂ∑ÆËøûÊé•ÊÄùÊÉ≥Ôºå‰øùÁïôÂ∫ïËâ≤ÔºåÂä†ÂÖ•ÂÜ≤Âáª)
        feat_f_raw = feat_cf_raw + gate * e_emb

        # üî•üî•üî•„ÄêÊ†∏ÂøÉ‰øÆÊîπÁÇπ 2„ÄëÂº∫Âà∂Â∫îÁî® LayerNorm üî•üî•üî•
        # ËøôÂ∞±ÊòØÁ†¥Â±ÄÁöÑÂÖ≥ÈîÆÔºÅÂº∫Âà∂ÊãâÂπ≥‰∏§‰∏™ÂêëÈáèÁöÑÊ®°Èïø„ÄÇ
        feat_cf = self.feature_norm(feat_cf_raw)
        feat_f = self.feature_norm(feat_f_raw)

        # --- C. È¢ÑÊµãËæìÂá∫ ---
        # ‰ΩøÁî®ÂΩí‰∏ÄÂåñÂêéÁöÑ‚Äú‰∫ãÂÆûÁâπÂæÅ‚ÄùËøõË°åÊúÄÁªàÈ¢ÑÊµã
        final_pred_logits = self.classifier(feat_f)
        final_pred_prob = torch.sigmoid(final_pred_logits)

        # ËøîÂõûÂÜÖÂÆπËØ¥Êòé:
        # final_pred_prob: Áî®‰∫éËÆ°ÁÆó MCC, F1
        # final_pred_logits: Áî®‰∫éËÆ°ÁÆó BCE Loss (L_Pred)
        # trend_logits: Áî®‰∫éËÆ°ÁÆó L_Base (Âü∫Á∫øÊçüÂ§±)
        # None, None: Âç†‰ΩçÁ¨¶ (Â¶ÇÊûúÊúâ shock_f, shock_cf ÂçïÁã¨ËæìÂá∫ÂèØÊîæËøôÈáå)
        # feat_f: ÂΩí‰∏ÄÂåñÂêéÁöÑ‰∫ãÂÆûÁâπÂæÅ (Áî®‰∫é L_Ortho, L_Triplet) -> Norm ~ 3.8
        # feat_cf: ÂΩí‰∏ÄÂåñÂêéÁöÑÂèç‰∫ãÂÆûÁâπÂæÅ (Áî®‰∫é L_Ortho, L_Triplet) -> Norm ~ 3.8
        # None, None: Âç†‰ΩçÁ¨¶

        return (final_pred_prob, final_pred_logits, trend_logits,
                None, None,
                feat_f, feat_cf,
                None, None)